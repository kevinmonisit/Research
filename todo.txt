To-do:

Learning How to Pipeline => Done

Feature Importance
    RECFV - check this one out again.
    Ranking => Done

Data binning (DataCamp) Done
    Calculating variance in the cross validation score

Scaling Data DONE
maybe look into it more

Create Tests DONE

Imputing Data DONE
    Changing TRANSFER into None Types and check what happens

Check this decision tree plot out:
https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_regression.html

Testing Different Machine Learning Models

Fine-Tuning The Machine Learning Models
    Doing a Grid Search --> DONE

Take care of other variables

Split Test data and train data

Clean up code
    Needs Cleaning: 8/16/2020

Plot the results and see how it works out.
    Does it fail to predict outliers or high absences??

Test out Bayesian/Coarse to Fine hyperparameter tuning

Implement KFolds

Use SVMs

Look around DataCamp Courses and check if there's anything interesting
after all the steps

=======================================

Finishing up Statistical Thinking Course
    part one DONE
    part two
    taking notes

Doing the Other Statistics Course

Applying Hacker Statistics on the dataset

Adding the rest of the data

======================================

AFTER EVERYTHING IS DONE
Write up the paper.
Write up the literature
?????
profit.


========== To do log ======
8/16/2020

Work on cleaning up some code (fix the jupyter notebooks)
    Done with model_setup stuff
    Will fix jupyter notebooks for feature_testing later. It's not important.

Add new models (from academic papers) --> DONE?
Train_test_split implementation --> DONE
Add new data





