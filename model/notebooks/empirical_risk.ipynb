{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/\n",
    "\n",
    "Bagging classifiers is the best way to defeat over-fitting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import model.temporary.testing_k_folds as driver\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from model.multi_models import ModelWrapper, get_model_wrapper_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "- i = get classification probabilities\n",
    "- determine the bins\n",
    "- determine students that fit within their\n",
    "respective bins\n",
    "- determine those who are TP and FP\n",
    "  (probably determined beforehand somehow)\n",
    "- loop through student list, summing\n",
    "  all the empirical risks and then getting\n",
    "  the mean\n",
    "- Plot\n",
    "\n",
    "- The empirical risk curve will most likely\n",
    "  not resemble the paper, so there might\n",
    "  need to be changes.\n",
    "'''\n",
    "\n",
    "model_pipeline, X_test, y_test = driver.get_model_pipeline()\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each bin object in the bins array will hold information regarding the\n",
    "distribution of students. More than that, it will hold information regarding\n",
    "the number of true positives out of the true positive and negatives."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Bin:\n",
    "    total_instances = 0\n",
    "    real_positives = 0\n",
    "    upper_range = 0\n",
    "    lower_range = 0\n",
    "    index = 0\n",
    "    empirical_risk = 0\n",
    "\n",
    "    def __init__(self, index, number_of_bins):\n",
    "        ranges = 1 / number_of_bins\n",
    "        self.upper_range = (index+1) * ranges\n",
    "        self.lower_range = (self.upper_range - ranges) - 0.001\n",
    "        self.index = index\n",
    "\n",
    "    def add_student(self, is_real_positive):\n",
    "        self.total_instances += 1\n",
    "\n",
    "        if is_real_positive:\n",
    "            self.real_positives += 1\n",
    "\n",
    "        self.empirical_risk = self.real_positives / self.total_instances\n",
    "\n",
    "number_of_bins_test = 4\n",
    "bins_test = [Bin(x, number_of_bins_test) for x in range(0,number_of_bins_test)]\n",
    "\n",
    "def add_to_bin(bin_array, probability, actual_positive):\n",
    "    \"\"\"\n",
    "    The purpose of add_to_bin is to initialize the bin objects\n",
    "    in a list. It does not create the bin object in the list itself.\n",
    "\n",
    "    :param bin_array: list of correctly initialized bin objects\n",
    "    :param probability: the risk score of the student\n",
    "    :param actual_positive: whether the student is actually positive\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if len(bin_array) == 0 or isinstance(bin_array[0], Bin) is False:\n",
    "        raise ValueError(\"Bin array was not initialized correctly\")\n",
    "\n",
    "    if probability > 1 or probability < 0:\n",
    "        raise ValueError(\"Probability must be in range (0, 1)\")\n",
    "    \n",
    "    for k in bin_array:\n",
    "        #bins encompass values of lower range <= x < upper_range\n",
    "        if probability < k.upper_range:\n",
    "            k.add_student(actual_positive)\n",
    "            return\n",
    "\n",
    "        # special case where one's determined probability IS one\n",
    "        if probability == 1 and k.upper_range == 1:\n",
    "            k.add_student(actual_positive)\n",
    "            return\n",
    "\n",
    "    raise RuntimeError(\"Could not find bin for a student. Bin array was \\\n",
    "                       initialized wrongly\")\n",
    "\n",
    "## Tests ##\n",
    "add_to_bin(bins_test, 0.11, True)\n",
    "add_to_bin(bins_test, 0.276, True)\n",
    "add_to_bin(bins_test, 0.25, True)\n",
    "\n",
    "assert bins_test[0].total_instances == 1\n",
    "assert bins_test[1].total_instances == 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 1]\n",
      " [1 7]]\n",
      "8\n",
      "BIN 0\n",
      "Instances:  7\n",
      "Actual positives:  1\n",
      "Empirical Risk of Bin:  0.14285714285714285\n",
      "BIN 1\n",
      "Instances:  1\n",
      "Actual positives:  0\n",
      "Empirical Risk of Bin:  0.0\n",
      "BIN 2\n",
      "Instances:  4\n",
      "Actual positives:  3\n",
      "Empirical Risk of Bin:  0.75\n",
      "BIN 3\n",
      "Instances:  4\n",
      "Actual positives:  4\n",
      "Empirical Risk of Bin:  1.0\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = []\n",
    "# contain student info and their probability in order to sort them\n",
    "student_prediction_list = []\n",
    "y_pred = [] #this is for the confusion matrix\n",
    "\n",
    "# At this point, the model has not predicted any students yet.\n",
    "# The loop goes through the X_test array and allows the model\n",
    "# to individually predict each student. This is done in order\n",
    "# to get individual information about each data point prediction.\n",
    "# With a simple prediction list, you cannot know whether\n",
    "# the student is a false or true positive because row numbers\n",
    "# of nparrays and dataframes do not align for some reason.\n",
    "for i in range(X_test.shape[0]):\n",
    "    student_data_point = X_test.iloc[i].values.reshape(1,-1)\n",
    "    pred = model_pipeline.predict(student_data_point)\n",
    "    y_pred_prob = model_pipeline.best_estimator_['model'].predict_proba(student_data_point)[:, 1]\n",
    "\n",
    "    #whether a student was positive, regardless if false positive or true positive\n",
    "    student_actually_positive = y_test.iloc[i] == True\n",
    "\n",
    "    predictions.append({\"prediction\": pred[0],\n",
    "                        \"student_actually_positive\": student_actually_positive,\n",
    "                        \"probability\": y_pred_prob[0]})\n",
    "\n",
    "    student_prediction_list.append({\"student\": student_data_point,\n",
    "                                    \"probability\": y_pred_prob[0]})\n",
    "\n",
    "    y_pred.append(pred)\n",
    "\n",
    "matrix = confusion_matrix(y_test, np.asarray(y_pred).reshape(-1,1))\n",
    "print(matrix)\n",
    "\n",
    "\n",
    "#\n",
    "number_of_bins = 4\n",
    "#### INITIALIZING THE BIN ARRAY\n",
    "bins = [Bin(x, number_of_bins)for x in range(0,number_of_bins)]\n",
    "\n",
    "#COUNT NUMBER OF TRUE POSITIVES\n",
    "count = 0\n",
    "for i in predictions:\n",
    "    if i['student_actually_positive']:\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "\n",
    "for student_results in predictions:\n",
    "    add_to_bin(bins, student_results['probability'], student_results['student_actually_positive'])\n",
    "\n",
    "instances_count = 0\n",
    "for i in bins:\n",
    "    print(\"BIN %i\" % i.index)\n",
    "    instances_count += i.total_instances\n",
    "    print(\"Instances: \", i.total_instances)\n",
    "    print(\"Actual positives: \", i.real_positives)\n",
    "    print(\"Empirical Risk of Bin: \", i.empirical_risk)\n",
    "\n",
    "print(instances_count)\n",
    "\n",
    "student_prediction_list.sort(key=lambda x: x[\"probability\"])\n",
    "\n",
    "# for student in student_prediction_list:\n",
    "#     print(student[\"student\"])\n",
    "#     print(student[\"probability\"])\n",
    "#     print(\"======\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import model.model_setup as ms\n",
    "import model.temporary.testing_k_folds as tk\n",
    "\n",
    "class EmpiricalRiskModelWrapper:\n",
    "\n",
    "    def __init__(self, classifier: ModelWrapper, amount_of_bins=4):\n",
    "        if classifier.is_fit() is False:\n",
    "            raise ValueError(\"Model must be fitted!\")\n",
    "\n",
    "        self.bins_initialized = False\n",
    "        self.model_wrapper = classifier\n",
    "        self.y_pred_with_info = []\n",
    "        self.bins_of_model = [Bin(x, amount_of_bins) for x in range(0, amount_of_bins)]\n",
    "        self.y_values = []\n",
    "\n",
    "    def predict(self):\n",
    "        return self.model_wrapper.predict()\n",
    "\n",
    "    def get_prediction_info(self, X_test_, y_test_):\n",
    "        \"\"\"\n",
    "        This function predicts each student individually while also\n",
    "        obtaining extra information regarding the prediction that\n",
    "        cannot be done with normal model.predict(X_test).\n",
    "\n",
    "        :param X_test_: x_test\n",
    "        :param y_test_: y_test\n",
    "        :return: predictions with extra useful information\n",
    "        \"\"\"\n",
    "        for j in range(X_test_.shape[0]):\n",
    "            data_point = X_test_.iloc[j].values.reshape(1,-1)\n",
    "            model_pred = self.model_wrapper.predict(data_point)\n",
    "            y_pred_probability = \\\n",
    "                self.model_wrapper.model.best_estimator_['model'].predict_proba(data_point)[:, 1]\n",
    "\n",
    "            #whether a student was positive, regardless if false positive or true positive\n",
    "            positive_student = y_test_.iloc[j] == True\n",
    "\n",
    "            self.y_pred_with_info.append({\"prediction\": model_pred[0],\n",
    "                                \"positive_student\": positive_student,\n",
    "                                \"probability\": y_pred_probability[0]})\n",
    "\n",
    "\n",
    "        return self.y_pred_with_info\n",
    "\n",
    "    def print_bin_info(self):\n",
    "        if self.model_wrapper.is_fit() is False:\n",
    "            raise NotFittedError()\n",
    "\n",
    "        if len(self.y_pred_with_info) == 0:\n",
    "            raise RuntimeError(\"get_prediction_info has not been called yet!\")\n",
    "\n",
    "        if self.bins_initialized is False:\n",
    "            raise RuntimeError(\"Initialize your bins first. Bins are\"\n",
    "                               \"generic bins.\")\n",
    "        instances_count_ = 0\n",
    "        for bin_element in bins:\n",
    "            print(\"BIN %i\" % bin_element.index)\n",
    "            instances_count_ += bin_element.total_instances\n",
    "            print(\"Instances: \", bin_element.total_instances)\n",
    "            print(\"Actual positives: \", bin_element.real_positives)\n",
    "            print(\"Empirical Risk of Bin: \", bin_element.empirical_risk)\n",
    "\n",
    "        print(\"Instances count of %s: %i\" % self.model_wrapper.model_name, instances_count_)\n",
    "\n",
    "    def get_empirical_risk(self):\n",
    "        \"\"\"\n",
    "        Calculates empirical risks done by a specific model\n",
    "\n",
    "        :return: list of bins with their calculated mean empirical risk\n",
    "        \"\"\"\n",
    "\n",
    "        if self.model_wrapper.is_fit() is False:\n",
    "            raise NotFittedError()\n",
    "\n",
    "        if len(self.y_pred_with_info) == 0:\n",
    "            raise RuntimeError(\"get_prediction_info has not been called yet!\")\n",
    "\n",
    "        self.bins_initialized = True\n",
    "\n",
    "        print(self.y_pred_with_info)\n",
    "        for results in self.y_pred_with_info:\n",
    "\n",
    "            add_to_bin(self.bins_of_model,\n",
    "                       results['probability'],\n",
    "                       results['positive_student'])\n",
    "\n",
    "        for bin_ in self.bins_of_model:\n",
    "            self.y_values.append(bin_.empirical_risk)\n",
    "\n",
    "        return self.model_wrapper.model_name, self.bins_of_model, self.y_values\n",
    "\n",
    "\n",
    "#################### GRAPHING EMPIRICAL RISK #######################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students on reduced lunch: 23\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Scoring used:  recall\n",
      "Best parameters:  {}\n",
      "Best/Mean score using best parameters:  0.41666666666666663\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Scoring used:  recall\n",
      "Best parameters:  {}\n",
      "Best/Mean score using best parameters:  0.5166666666666667\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Scoring used:  recall\n",
      "Best parameters:  {}\n",
      "Best/Mean score using best parameters:  0.5499999999999999\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Scoring used:  recall\n",
      "Best parameters:  {}\n",
      "Best/Mean score using best parameters:  0.5499999999999999\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-2286429d0934>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;31m# convert all the model wrappers into empirical risk model objects\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel_wrappers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m     \u001B[0mi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m     \u001B[0memp_model_wrapper\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mEmpiricalRiskModelWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Research/model/multi_models.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, random_search, max_iter, refit)\u001B[0m\n\u001B[1;32m     89\u001B[0m             \u001B[0;31m# ROC/AUC Preliminary Variables\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"y_test\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 91\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"y_pred_prob\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_pipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'model'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m             \u001B[0;31m# model becomes a grid search object.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/again/lib/python3.7/site-packages/sklearn/svm/_base.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    655\u001B[0m         \u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    656\u001B[0m         \"\"\"\n\u001B[0;32m--> 657\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_proba\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    658\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_predict_proba\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    659\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/again/lib/python3.7/site-packages/sklearn/svm/_base.py\u001B[0m in \u001B[0;36m_check_proba\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    622\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_check_proba\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    623\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprobability\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 624\u001B[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001B[0m\u001B[1;32m    625\u001B[0m                                  \" probability=False\")\n\u001B[1;32m    626\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_impl\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'c_svc'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'nu_svc'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "random_state = 1\n",
    "test_size = 0.2\n",
    "\n",
    "#### MODEL SET UP #############\n",
    "student_data = ms.get_student_data('../../data/data.csv', bin=False)\n",
    "features = [\"A8\", \"Has_504\", \"Student on Free or Reduced Lunch\", \"IEP/Specialized\"]\n",
    "\n",
    "models = [RandomForestClassifier(random_state=1),\n",
    "          AdaBoostClassifier(random_state=1),\n",
    "          LogisticRegression(),\n",
    "          # read more about the probability\n",
    "          # of SVC. May be problematic.\n",
    "          SVC(probability=True)]\n",
    "\n",
    "# contains empirical risk model wrapper objects\n",
    "model_wrappers = get_model_wrapper_list(models,\n",
    "                                           student_data[features],\n",
    "                                           student_data['ChronicallyAbsent_in_HS'],\n",
    "                                           test_size=test_size,\n",
    "                                           random_state=random_state)\n",
    "\n",
    "emp_model_wrapper = []\n",
    "# convert all the model wrappers into empirical risk model objects\n",
    "for i in model_wrappers:\n",
    "    i.fit()\n",
    "    emp_model_wrapper.append(EmpiricalRiskModelWrapper(i))\n",
    "\n",
    "#### GRAPHING SET UP #############\n",
    "number_of_bins = 4\n",
    "graph_x_values = []\n",
    "graph_y_values = []\n",
    "\n",
    "# initialize x_values for the graph\n",
    "upper_range = 1 / number_of_bins\n",
    "for i in range(0,number_of_bins):\n",
    "    graph_x_values.append(upper_range)\n",
    "    upper_range += (1 / number_of_bins)\n",
    "\n",
    "##TODO: X_TEST????? WHERE DOES IT COME FROM?\n",
    "\n",
    "for model_wrapper in emp_model_wrapper:\n",
    "    # initialize each model wrapper objec\n",
    "    model_wrapper.get_prediction_info(X_test, y_test)\n",
    "\n",
    "    # get empirical risk returns tuple. y_values are third in the tuple\n",
    "    graph_y_values.append(model_wrapper.get_empirical_risk()[2])\n",
    "\n",
    "print(graph_x_values)\n",
    "print(len(graph_y_values))\n",
    "\n",
    "ax = sns.lineplot(x=graph_x_values, y=graph_y_values[0])\n",
    "\n",
    "for y in graph_y_values:\n",
    "    sns.lineplot(x=graph_x_values, y=y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Graphing mean empirical risk\n",
    "#\n",
    "# y_values = [] # mean empirical risk of each bin\n",
    "# x_values = []\n",
    "# for i in bins:\n",
    "#     y_values.append(i.empirical_risk)\n",
    "#     x_values.append(i.upper_range)\n",
    "#\n",
    "# print(y_values)\n",
    "#\n",
    "#\n",
    "# x_values = [0.25, 0.5, 0.75, 1]\n",
    "# y_values = [0, 0.222, 0.85714, 0]\n",
    "# # AdaBoost\n",
    "#\n",
    "# # plt.pyplot.figure(figsize=(10,5))\n",
    "#\n",
    "# ax = sns.lineplot(x=x_values, y=y_values)\n",
    "# ax.set_xlabel(\"Upper Percentiles of Bins\")\n",
    "# ax.set_ylabel(\"Mean Empirical Risk\")\n",
    "# ax.set_xticks([0.25, 0.5, 0.75, 1])\n",
    "#\n",
    "# # Random Forest\n",
    "# y_values = [0.14, 0, 0.75, 1]\n",
    "# sns.lineplot(x=x_values, y=y_values)\n",
    "#\n",
    "# # Linear Regression\n",
    "# y_values = [0.166, 0.5, 0.67, 1]\n",
    "# sns.lineplot(x=x_values, y=y_values)\n",
    "#\n",
    "# fig = ax.get_figure()\n",
    "#\n",
    "# width  = 3.5\n",
    "# height = width / 1.618\n",
    "# fig.subplots_adjust(left=.20, bottom=.24, right=.99, top=.97)\n",
    "# fig.set_size_inches(width, height)\n",
    "# fig.savefig('myimage.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-787e714",
   "language": "python",
   "display_name": "PyCharm (2020 Research)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}