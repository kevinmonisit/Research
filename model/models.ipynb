{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# easy way of accessing A_6, A_7, ... A_N columns\n",
    "def column_list(letter, start, end):\n",
    "    return [\"%s%d\" % (letter, i) for i in range(start, end)]\n",
    "\n",
    "\n",
    "def remove_outliers(column, target, first, second):\n",
    "    non_outliers = target.between(target.quantile(first), target.quantile(second))\n",
    "\n",
    "    for index in range(0, len(column)):\n",
    "        if ~non_outliers[index]:\n",
    "            column.drop(index, inplace=True)\n",
    "\n",
    "\n",
    "# convert strings to int type even if it's a float\n",
    "# replace by median or mean?\n",
    "def convert_stat(x, new_value=0):\n",
    "    if not isinstance(x, int):\n",
    "\n",
    "        if not isinstance(x, float) and '.' not in x:\n",
    "            return new_value if x == \"TRANSFER\" else int(x)\n",
    "        else:\n",
    "            return new_value if x == \"TRANSFER\" else int(float(x))\n",
    "\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "class SumTransformer(BaseEstimator):\n",
    "\n",
    "    # set new_value to None if Pipeline contains SimpleImputer\n",
    "    # this is for absences and tardies since somet students are\n",
    "    # transfer students. The placeholder in the CSV is the string \"TRANSFER\"\n",
    "    def __init__(self, new_value=0, bins=1):\n",
    "        self.new_value = new_value\n",
    "        self.bins = bins\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        # change to for i in [\"A\", \"T\"] to include tardies if need be\n",
    "        for i in [\"A\"]:\n",
    "\n",
    "            # corrects the values in the data frame that will be used in the training models\n",
    "            for j in column_list(i, 6, 9):\n",
    "                df[j] = df[j].apply(convert_stat, self.new_value)\n",
    "          #      df[j] = np.array(np.floor(np.array(df[j]) / float(self.bins)))\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After setting up the functions needed for pre-processing, I set up the data. There are necessary pre-processing\n",
    "*before* the actual pre-processing. Because some numerical columns contain string types, it is necessary\n",
    "to convert them. Also, outliers are determined before the split (or pipeline), and removed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.43076923 16.23076923 15.76923077 17.93846154 19.58333333]\n"
     ]
    }
   ],
   "source": [
    "student_data = pd.read_csv(\"../data/High School East Student Data - Sheet1.csv\")\n",
    "features = [\"A6\", \"A7\", \"A8\"]\n",
    "student_data[\"AbsencesSum_HS\"] = 0\n",
    "\n",
    "# Pipeline doesn't allow transformations on the target label\n",
    "# so I have to do transformations outside of Pipeline in order\n",
    "# to sum all absences in High School for each student.\n",
    "for j in column_list(\"A\", 9, 13):\n",
    "    student_data[j] = student_data[j].apply(convert_stat)\n",
    "\n",
    "student_data[\"AbsencesSum_HS\"] = student_data[column_list('A', 9, 13)].sum(axis=1)\n",
    "\n",
    "# because we've created the total absences in high school column\n",
    "# we are now able to eliminate outliers in the dataset.\n",
    "remove_outliers(student_data, student_data[\"AbsencesSum_HS\"], 0, 0.95)\n",
    "\n",
    "pre_process = ColumnTransformer(remainder='passthrough',\n",
    "                                transformers=[('categories', OneHotEncoder(), [\"Gender\", \"IEP/Specialized\"])])\n",
    "\n",
    "def run_test(model, data, target, bins=1, model_name=\"model\"):\n",
    "    pipeline = Pipeline(steps=[('number_fix', SumTransformer(bins=bins)),\n",
    "                                # ('pre_process', pre_process),\n",
    "                                 (model_name, model)\n",
    "                                 ])\n",
    "    scores = -1 * cross_val_score(pipeline,\n",
    "                              data[features],\n",
    "                              data[target],\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "    return scores\n",
    "\n",
    "### Sorta like unit testing but in jupyter\n",
    "test = run_test(DecisionTreeRegressor(random_state=1), student_data, \"AbsencesSum_HS\")\n",
    "prior_run = np.array([23.43076923, 16.23076923, 15.76923077, 17.93846154, 19.58333333])\n",
    "\n",
    "if not np.allclose(test, prior_run, atol=0.001):\n",
    "    raise Exception(\"Unintended modification to pre-processing!!! Fix it!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Feature Engineering Tests\n",
    "## 2.1 Binning the Data\n",
    "https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import copy as cp\n",
    "\n",
    "data_copy = cp.deepcopy(student_data)\n",
    "\n",
    "#comparing fixed width binning and dynamic width binning\n",
    "data_copy[\"HS_AB_FIXED\"] = np.array(np.floor(np.array(data_copy[\"AbsencesSum_HS\"]) / 5.))\n",
    "\n",
    "np.array(run_test(DecisionTreeRegressor(random_state=1), data_copy, \"HS_AB_FIXED\", bins=5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4.05128205, 3.87179487, 3.15384615, 3.71794872, 5.08333333])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first model I will test is the Decision Tree Regressor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nmodel_pipeline.fit(student_data[features], student_data[\"AbsencesSum_HS\"])\\n\\nimportances = model_pipeline.named_steps[\\'Decision Tree\\'].feature_importances_\\nindices = np.argsort(importances)[::-1]\\n\\n# Print the feature ranking\\nprint(\"Feature ranking:\")\\n\\nfor f in range(7):\\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\\n\\nscores = -1 * cross_val_score(run_test(tree, \"Decision Tree\"),\\n                              student_data[features],\\n                              student_data[\"AbsencesSum_HS\"],\\n                              cv=5,\\n                              scoring=\\'neg_mean_absolute_error\\')\\n\\n#print(np.mean(scores))\\n'"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "\"\"\"\n",
    "model_pipeline.fit(student_data[features], student_data[\"AbsencesSum_HS\"])\n",
    "\n",
    "importances = model_pipeline.named_steps['Decision Tree'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(7):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "scores = -1 * cross_val_score(run_test(tree, \"Decision Tree\"),\n",
    "                              student_data[features],\n",
    "                              student_data[\"AbsencesSum_HS\"],\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "#print(np.mean(scores))\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the optimal number of features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = Pipeline(steps=[('number_fix', SumTransformer()),\n",
    "                                 ('pre_process', pre_process),\n",
    "                                 ('Decision Tree', tree)\n",
    "                                 ])\n",
    "\n",
    "\n",
    "print(\"hell\")\n",
    "%matplotlib inline\n",
    "\n",
    "#RVEFC for determining optimal number of features??"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (2020 Research)",
   "language": "python",
   "name": "pycharm-911807b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}